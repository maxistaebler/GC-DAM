{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from gliner import GLiNER\n",
    "import ollama\n",
    "from node2vec import Node2Vec\n",
    "import networkx as nx\n",
    "import plotly\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import ast\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GLiNER with the base model\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_mediumv2.1\")\n",
    "def create_splitter():\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=150,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    return splitter\n",
    "\n",
    "labels = [\n",
    "    \"person\", \"award\", \"date\", \"competitions\", \"teams\", \"organization\", \"location\", \"event\", \"product\", \n",
    "    \"quantity\", \"money\", \"percent\", \"time\", \"gpe\", \"facility\", \"language\", \"work_of_art\", \"law\", \"nationality\", \n",
    "    \"title\", \"field_of_study\", \"measurement\", \"technology\"\n",
    "]\n",
    "\n",
    "splitter = create_splitter()\n",
    "\n",
    "GOOGLE_EMBEDDING_DF = \"google_embeddings_stella_1.5b.csv\"\n",
    "AMAZON_EMBEDDING_DF = \"amazon_embeddings_stella_1.5b.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download pre-trained embeddings\n",
    "\n",
    "[amazon](https://drive.google.com/file/d/1JSn-fFtP_o7T3XxKdRrwLP1hyy27wzpf/view?usp=sharing)\n",
    "\n",
    "[google](https://drive.google.com/file/d/1IYr8Of23hrdkDkc24hTE7ixWVIthCSg2/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Entferne alle Satzzeichen (Punctuation)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Wandle den gesamten Text in Kleinbuchstaben um\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "amazon_df = pd.read_csv('../datasets/amazon-google/Amazon.csv', encoding='unicode_escape')\n",
    "amazon_df.fillna('', inplace=True)\n",
    "amazon_df['title'] = amazon_df['title'].apply(lambda x: clean_text(x))\n",
    "amazon_df['description'] = amazon_df['description'].apply(lambda x: clean_text(x))\n",
    "\n",
    "google_df = pd.read_csv('../datasets/amazon-google/GoogleProducts.csv', encoding='unicode_escape')\n",
    "google_df.fillna('', inplace=True)\n",
    "google_df['name'] = google_df['name'].apply(lambda x: clean_text(x))\n",
    "google_df['description'] = google_df['description'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(amazon_df))\n",
    "print(len(google_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google_embeddings = []\n",
    "# for idx, row in tqdm(google_df.iterrows()):\n",
    "#     t = f\"The manufcaturer of the product is: {row['manufacturer']}. The Title is: {row['name']}. The price is: {row['price']}. And now the description: {row['description']}\"\n",
    "#     response = ollama.embeddings(model=\"Losspost/stella_en_1.5b_v5\", prompt=t)\n",
    "#     google_embeddings.append(response['embedding'])\n",
    "# amazon_embeddings = []\n",
    "# for idx, row in tqdm(amazon_df.iterrows()):\n",
    "#     t = f\"The manufcaturer of the product is: {row['manufacturer']}. The Title is: {row['title']}. The price is: {row['price']}. And now the description: {row['description']}\"\n",
    "#     response = ollama.embeddings(model=\"Losspost/stella_en_1.5b_v5\", prompt=t)\n",
    "#     amazon_embeddings.append(response['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google_embd = pd.DataFrame(google_embeddings, index=google_df['id']).reset_index()\n",
    "# google_embd.to_csv(GOOGLE_EMBEDDING_DF)\n",
    "\n",
    "# amazon_embd = pd.DataFrame(amazon_embeddings, index=amazon_df['id']).reset_index()\n",
    "# amazon_embd.to_csv(AMAZON_EMBEDDING_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_embd = pd.read_csv(GOOGLE_EMBEDDING_DF)\n",
    "amazon_embd = pd.read_csv(AMAZON_EMBEDDING_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ER Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_nodes = []\n",
    "\n",
    "for idx, row in tqdm(google_df.iterrows()):\n",
    "    text = f\"The manufcaturer of the product is: {row['manufacturer']}. The Title is: {row['name']}. The price is: {row['price']}. And now the description: {row['description']}\"\n",
    "    # Load Text\n",
    "    texts = splitter.create_documents([text])\n",
    "    # Split Text\n",
    "    pages = splitter.split_documents(texts)\n",
    "    for p in pages:\n",
    "        entities = model.predict_entities(p.page_content, labels, threshold=0.5)\n",
    "        for entity in entities:\n",
    "            google_nodes.append((entity[\"text\"].lower(), entity[\"label\"].lower(), row['id'], 'google'))\n",
    "            # print(entity[\"text\"].lower(), \"=>\", entity[\"label\"].lower())\n",
    "\n",
    "print(len(list(set(google_nodes))))\n",
    "\n",
    "#######\n",
    "\n",
    "amazon_nodes = []\n",
    "\n",
    "for idx, row in tqdm(amazon_df.iterrows()):\n",
    "    text = f\"The manufcaturer of the product is: {row['manufacturer']}. The Title is: {row['title']}. The price is: {row['price']}. And now the description: {row['description']}\"\n",
    "    # Load Text\n",
    "    texts = splitter.create_documents([text])\n",
    "    # Split Text\n",
    "    pages = splitter.split_documents(texts)\n",
    "    for p in pages:\n",
    "        entities = model.predict_entities(p.page_content, labels, threshold=0.5)\n",
    "        for entity in entities:\n",
    "            amazon_nodes.append((entity[\"text\"].lower(), entity[\"label\"].lower(), row['id'], 'amazon'))\n",
    "            # print(entity[\"text\"].lower(), \"=>\", entity[\"label\"].lower())\n",
    "\n",
    "print(len(list(set(amazon_nodes))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = google_nodes + amazon_nodes\n",
    "\n",
    "with open('./assets/google_amazon_er_liste.pkl', 'wb') as f:\n",
    "    pickle.dump(nodes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KG Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_edge_weight(G, u, v):\n",
    "    if G.has_edge(u, v):\n",
    "        G[u][v]['weight'] += 1\n",
    "    else:\n",
    "        # Füge die Kante hinzu, falls sie noch nicht existiert, mit Gewicht 1\n",
    "        G.add_edge(u, v, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "G = nx.Graph()\n",
    "## Add Nodes\n",
    "for node in nodes:\n",
    "    if not G.has_node(node[0]):\n",
    "        G.add_node(\n",
    "            node[0].lower(),\n",
    "            type=\"entity\"\n",
    "        )\n",
    "    if not G.has_node(node[1]):\n",
    "        G.add_node(\n",
    "            node[1].lower(),\n",
    "            type=\"label\"\n",
    "        )\n",
    "    if not G.has_node(node[2]):\n",
    "        G.add_node(\n",
    "            node[2].lower(),\n",
    "            type=\"product\"\n",
    "        )\n",
    "    # if not G.has_node(node[3]):\n",
    "    #     G.add_node(\n",
    "    #         node[3].lower(),\n",
    "    #         type=\"dataset\"\n",
    "    #     )\n",
    "    # Add tuple edges\n",
    "    increment_edge_weight(G, node[0].lower(), node[1].lower())\n",
    "    increment_edge_weight(G, node[1].lower(), node[2].lower())\n",
    "    increment_edge_weight(G, node[0].lower(), node[2].lower())\n",
    "# Beispiel: Anzahl der Knoten und Kanten anzeigen\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_gexf(G, \"./graphs/n2v_amazon_google_graph_full.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec = Node2Vec(G, dimensions=128, walk_length=40, num_walks=100, workers=2)\n",
    "model = node2vec.fit(window=10, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('./assets/KG_amazon_google_n2v_embedding.csv')\n",
    "model.save('./assets/KG_amazon_google_n2v_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve node embeddings\n",
    "node_ids = model.wv.index_to_key  # list of node IDs\n",
    "node_labels = model.wv.key_to_index\n",
    "node_embeddings = model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_embd = pd.DataFrame(node_embeddings, index=node_labels).reset_index()\n",
    "n2v_embd.rename(columns = {'index':'product'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_idxs = list(google_df['id'])\n",
    "amazon_idxs = list(amazon_df['id'])\n",
    "\n",
    "n2v_embd_google = n2v_embd[n2v_embd['product'].isin(google_idxs)]\n",
    "n2v_embd_amazon = n2v_embd[n2v_embd['product'].isin(amazon_idxs)]\n",
    "print(len(n2v_embd_google))\n",
    "print(len(n2v_embd_amazon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=list(n2v_embd_google['product'].values) + list(n2v_embd_amazon['product'].values)\n",
    "id_dataset = {('google' if str(x).split(':')[0] == 'http' else 'amazon'): k for k, x in enumerate(l)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_embd_google['type'] = 'google'\n",
    "n2v_embd_amazon['type'] = 'amazon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_combined = pd.concat([n2v_embd_amazon, n2v_embd_google])\n",
    "n2v_combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_vectors = np.array(n2v_combined.drop(['product', 'type'], axis=1).to_numpy())\n",
    "cosine_n2v = cosine_similarity(n2v_vectors)\n",
    "cosine_n2v_df = pd.DataFrame(cosine_n2v, index=n2v_combined['product'], columns=n2v_combined['product'])\n",
    "cosine_n2v_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google is True -->Y Invertieren für Amazon\n",
    "cosine_dataset_id = [True if x in google_idxs else False for x in cosine_n2v_df.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_matching = pd.read_csv('../datasets/amazon-google/Amzon_GoogleProducts_perfectMapping.csv')\n",
    "matching_scores = []\n",
    "\n",
    "for i, (idx, row) in enumerate(cosine_n2v_df.iterrows()):\n",
    "    pm_amazon = perfect_matching[perfect_matching['idAmazon']==idx]['idGoogleBase'].values\n",
    "    pm_google = perfect_matching[perfect_matching['idGoogleBase']==idx]['idAmazon'].values\n",
    "    if idx in google_idxs:\n",
    "        f = pd.Series(cosine_dataset_id).values\n",
    "        d = cosine_n2v_df[f]\n",
    "        dd = d[d.index == idx].T\n",
    "        dd_f = dd[dd.index.isin(amazon_idxs)].sort_values(idx, ascending=False)\n",
    "        indices = np.where(np.isin(dd_f.index.values, pm_google))[0]\n",
    "        if len(indices) > 0:\n",
    "            tuple_out = [(x, dd_f.iloc[x][idx], 'google', idx, pm_google) for x in indices][0]\n",
    "            matching_scores.append(tuple_out)\n",
    "    elif idx in amazon_idxs:\n",
    "        f = ~pd.Series(cosine_dataset_id).values\n",
    "        d = cosine_n2v_df[f]\n",
    "        dd = d[d.index == idx].T\n",
    "        dd_f = dd[dd.index.isin(google_idxs)].sort_values(idx, ascending=False)\n",
    "        indices = np.where(np.isin(dd_f.index.values, pm_amazon))[0]\n",
    "        if len(indices) > 0:\n",
    "            tuple_out = [(x, dd_f.iloc[x][idx], 'amazon', idx, pm_amazon) for x in indices][0]\n",
    "            matching_scores.append(tuple_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(matching_scores, columns=['rank', 'score', 'dataset', 'index', 'perfect_match'])\n",
    "print(f\"Ideal Matching (%): {round(result_df['rank'].value_counts()[0] / len(result_df), 3) * 100}\")\n",
    "result_df.score.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_palette = sns.color_palette(['#FF33CC', '#39FF14', '#00FFFF', '#998650', '#E0BE36'])\n",
    "sns.set_palette(custom_palette)\n",
    "\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('talk')\n",
    "fig, ax = plt.subplots()\n",
    "# sns.set_context(\"notebook\", rc={\"lines.linewidth\": 3})\n",
    "fig.set_size_inches(8, 10)\n",
    "\n",
    "sns.scatterplot(data=result_df, x=\"rank\", y=\"score\", hue='dataset')\n",
    "sns.rugplot(data=result_df, x=\"rank\", y=\"score\", color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_embd['type'] = 'google'\n",
    "amazon_embd['type'] = 'amazon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_embd_combined = pd.concat([google_embd, amazon_embd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_vectors = np.array(description_embd_combined.drop(['id', 'type'], axis=1).to_numpy())\n",
    "cosine_descriptions = cosine_similarity(description_vectors)\n",
    "cosine_descriptions_df = pd.DataFrame(cosine_descriptions, index=description_embd_combined['id'], columns=description_embd_combined['id'])\n",
    "cosine_descriptions_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_matching = pd.read_csv('../datasets/amazon-google/Amzon_GoogleProducts_perfectMapping.csv')\n",
    "matching_scores = []\n",
    "\n",
    "cosine_dataset_id = [True if x in google_idxs else False for x in cosine_descriptions_df.index.values]\n",
    "\n",
    "for i, (idx, row) in enumerate(cosine_descriptions_df.iterrows()):\n",
    "    pm_amazon = perfect_matching[perfect_matching['idAmazon']==idx]['idGoogleBase'].values\n",
    "    pm_google = perfect_matching[perfect_matching['idGoogleBase']==idx]['idAmazon'].values\n",
    "    if idx in google_idxs:\n",
    "        f = pd.Series(cosine_dataset_id).values\n",
    "        d = cosine_descriptions_df[f]\n",
    "        dd = d[d.index == idx].T\n",
    "        dd_f = dd[dd.index.isin(amazon_idxs)].sort_values(idx, ascending=False)\n",
    "        indices = np.where(np.isin(dd_f.index.values, pm_google))[0]\n",
    "        if len(indices) > 0:\n",
    "            tuple_out = [(x, dd_f.iloc[x][idx], 'google', idx, pm_google) for x in indices][0]\n",
    "            matching_scores.append(tuple_out)\n",
    "    elif idx in amazon_idxs:\n",
    "        f = ~pd.Series(cosine_dataset_id).values\n",
    "        d = cosine_descriptions_df[f]\n",
    "        dd = d[d.index == idx].T\n",
    "        dd_f = dd[dd.index.isin(google_idxs)].sort_values(idx, ascending=False)\n",
    "        indices = np.where(np.isin(dd_f.index.values, pm_amazon))[0]\n",
    "        if len(indices) > 0:\n",
    "            tuple_out = [(x, dd_f.iloc[x][idx], 'amazon', idx, pm_amazon) for x in indices][0]\n",
    "            matching_scores.append(tuple_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_description = pd.DataFrame(matching_scores, columns=['rank', 'score', 'dataset', 'index', 'perfect_match'])\n",
    "print(f\"Ideal Matching (%): {round(result_df_description['rank'].value_counts()[0] / len(result_df_description), 3) * 100}\")\n",
    "result_df_description.score.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_palette = sns.color_palette(['#FF33CC', '#39FF14', '#00FFFF', '#998650', '#E0BE36'])\n",
    "sns.set_palette(custom_palette)\n",
    "\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('talk')\n",
    "fig, ax = plt.subplots()\n",
    "# sns.set_context(\"notebook\", rc={\"lines.linewidth\": 3})\n",
    "fig.set_size_inches(8, 10)\n",
    "\n",
    "sns.scatterplot(data=result_df_description, x=\"rank\", y=\"score\", hue='dataset')\n",
    "sns.rugplot(data=result_df_description, x=\"rank\", y=\"score\", color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kombination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = result_df.copy()\n",
    "final_result['rank'] = result_df['rank'].combine(result_df_description['rank'], min)\n",
    "final_result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Ideal Matching (%): {round(final_result['rank'].value_counts()[0] / len(final_result), 3) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_palette = sns.color_palette(['#FF33CC', '#39FF14', '#00FFFF', '#998650', '#E0BE36'])\n",
    "sns.set_palette(custom_palette)\n",
    "\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('talk')\n",
    "fig, ax = plt.subplots()\n",
    "# sns.set_context(\"notebook\", rc={\"lines.linewidth\": 3})\n",
    "fig.set_size_inches(8, 10)\n",
    "\n",
    "markers = {\"amazon\": \"X\", \"google\": \"X\"}\n",
    "# sns.scatterplot(data=result_df_description, x=\"rank\", y=\"score\", hue='dataset', alpha=0.07, style='dataset', markers='x')\n",
    "# sns.scatterplot(data=result_df, x=\"rank\", y=\"score\", hue='dataset', alpha=0.07, style='dataset', markers='x')\n",
    "sns.scatterplot(data=final_result, x=\"rank\", y=\"score\", hue='dataset')\n",
    "sns.rugplot(data=final_result, x=\"rank\", y=\"score\", color='black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
